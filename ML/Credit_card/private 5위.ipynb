{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f06a9278",
   "metadata": {},
   "source": [
    "비슷한 대회 : https://www.kaggle.com/c/home-credit-default-risk\n",
    "최종적으로 object형 변수는 따로 전처리를 하지 않고, catboost 모델에서 cat_features 파라미터로 전달하였을 때 가장 좋은 점수를 얻을 수 있었습니다.\n",
    "Category features를 사용하기 위해서는 One-Hot-Encoding등 데이터를 전처리할 필요가 있지만,\n",
    "Catboost에서는 사용자가 다른 작업을 하지 않아도 자동으로 이를 변환하여 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33ac844a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "283decdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ab30cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "train.drop(['index'],axis = 1,inplace = True)\n",
    "test.drop(['index'],axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96dd4011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def days_to_year(x):\n",
    "    return (x*-1)/365\n",
    "\n",
    "def minus(x):\n",
    "    return x*-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3bfaa9",
   "metadata": {},
   "source": [
    "# 이상치제거  \n",
    "다른 변수들은 이상ㅊ치 제거해도 큰 변화 없음.child_num은 값의 차이가 많이 났다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25cea547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier(train, column):\n",
    "    \n",
    "    df = train[column]\n",
    "    \n",
    "    # 1분위수\n",
    "    quan_25 = np.percentile(df.values, 25)\n",
    "    \n",
    "    # 3분위수\n",
    "    quan_75 = np.percentile(df.values, 75)\n",
    "    \n",
    "    iqr = quan_75 - quan_25\n",
    "    \n",
    "    lowest = quan_25 - iqr * 5\n",
    "    highest = quan_75 + iqr * 5\n",
    "    outlier_index = df[(df < lowest) | (df > highest)].index\n",
    "    print('outlier의 수 : ' , len(outlier_index))\n",
    "    print(df.iloc[outlier_index])\n",
    "    train.drop(outlier_index, axis = 0, inplace = True)\n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0324a069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlier의 수 :  6\n",
      "8462     14\n",
      "9021     14\n",
      "10731    19\n",
      "25313     7\n",
      "25390    14\n",
      "25638     7\n",
      "Name: child_num, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26451"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['child_num']\n",
    "for column in cols:  \n",
    "    train = remove_outlier(train,column)\n",
    "\n",
    "train.reset_index(drop = True,inplace = True)\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd923865",
   "metadata": {},
   "source": [
    "# 파생 변수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77503601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_var(data):\n",
    "    #개인 inx\n",
    "    data['personal_id'] = data['gender']+'-'+data['DAYS_BIRTH'].astype(str)+'-'+data['income_total'].astype(str)+'-'+data['income_type'].astype(str)\n",
    "    \n",
    "    data['personal_begin_id'] = data['gender']+'-'+data['DAYS_BIRTH'].astype(str)+'-'+data['income_total'].astype(str)+'-'+data['income_type'].astype(str)+'-'+data['begin_month'].astype(str)\n",
    "    \n",
    "    #이외의 변수들을 조합하여 변수 생성 : 이것도 모델 설명력을 올려줄까? \n",
    "    data['g_r_c'] = data['gender']+'-'+data['reality']+'-'+data['car']\n",
    "    data['p_w_e'] = data['phone'].astype(str)+'-'+data['work_phone'].astype(str)+'-'+data['email'].astype(str)\n",
    "    \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1eae11b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = add_var(train)\n",
    "test = add_var(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e681ef69",
   "metadata": {},
   "source": [
    "# 숫자형 변수 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "821085e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_preprocess(data):\n",
    "    #income total\n",
    "    #만단위로 생성\n",
    "    data['income_total'] = data['income_total']/10000\n",
    "    #편차 제곱 변수 생성\n",
    "    data['income_total_dev'] = (data['income_total'] - data['income_total'].mean())**2\n",
    "    #로그 변환\n",
    "    data['income_total_log'] = data['income_total'].apply(np.log1p)\n",
    "    \n",
    "    #DAYS_EMPLOYED\n",
    "    data.loc[data['DAYS_EMPLOYED']>=0,'DAYS_EMPLOYED']=0\n",
    "    #data.DAYS_EMPLOYED.apply(lambda x: 0 if x>=0 else x)\n",
    "    data['DAYS_EMPLOYED'] = data['DAYS_EMPLOYED'].apply(days_to_year)\n",
    "    #log trans\n",
    "    data['DAYS_EMPLOYED_log'] = data['DAYS_EMPLOYED'].apply(np.log1p)\n",
    "    \n",
    "    #begin_month\n",
    "    #양수처리\n",
    "    data['begin_month'] = data['begin_month'].apply(minus)\n",
    "    \n",
    "    #DAYS_BIRTH\n",
    "    #days to year\n",
    "    data['DAYS_BIRTH'] = data['DAYS_BIRTH'].apply(days_to_year)\n",
    "    \n",
    "    #Ratio var\n",
    "    data['EMPLOEYD_BIRTH_RATIO'] = data['DAYS_EMPLOYED']/data['DAYS_BIRTH']\n",
    "    data['INCOME_EMPLOYED_RATIO'] = data['income_total']/data['DAYS_EMPLOYED']\n",
    "    data['INCOME_BITH_RATIO'] = data['income_total']/data['DAYS_BIRTH']\n",
    "    \n",
    "    # 가족수 - 자식수\n",
    "    data['diff_fam_child'] = data['family_size'] - data['child_num']\n",
    "    # chid_num과 family_size는 다음과 같이 최대 2와 5가 되도록 전처리\n",
    "    data.loc[data['child_num'] >= 2,'child_num'] = 2\n",
    "    data.loc[data['family_size'] >= 5,'child_num'] = 5\n",
    "    # 가족수와 자녀수 sum 변수 추가\n",
    "    data['FAM_CHILD_SUM'] = data[['child_num', 'family_size']].sum(axis=1)\n",
    "    \n",
    "    #*income을 가족 수 및 자식 수로 나눈 비율\n",
    "    data['INCOME_FAM_RATIO'] = data['income_total']/data['family_size']\n",
    "    data['INCOME_child_num_RATIO'] = data['income_total']/data['child_num']\n",
    "    \n",
    "    #**일을하게 된 시점 변수 추가\n",
    "    data['BIRTH_MINUS_EMPLOYED'] = data['DAYS_BIRTH'] - data['DAYS_EMPLOYED']\n",
    "    # income total 변수에 before_EMPLOYED로 나눈 변수 추가\n",
    "    data['INCOME_BIRTH_MINUS_EMPLOYED_RATIO'] = data['income_total']/data['BIRTH_MINUS_EMPLOYED']\n",
    "    \n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95d8cffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = numeric_preprocess(train)\n",
    "test = numeric_preprocess(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884c88cd",
   "metadata": {},
   "source": [
    "# occcyp_type 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "76bbbbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def occype_process(data):\n",
    "    \n",
    "    # occyp_type 변수에만 있는 결측치를 'NAN' 값으로 대체\n",
    "    data['occyp_type'] = data['occyp_type'].fillna('NAN')\n",
    "    # 경력이 없고 직업군이 none인 사람은 no_work로 대체\n",
    "    data.loc[(data['DAYS_EMPLOYED'] == 0) & (data['occyp_type'] == 'NAN'), 'occyp_type'] = 'no_work'\n",
    "    print(data['occyp_type'].value_counts(), '\\n\\n')\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b45dbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_work                  8171\n",
      "Laborers                 4512\n",
      "Core staff               2646\n",
      "Sales staff              2539\n",
      "Managers                 2167\n",
      "Drivers                  1572\n",
      "High skill tech staff    1040\n",
      "Accountants               902\n",
      "Medicine staff            864\n",
      "Cooking staff             457\n",
      "Security staff            424\n",
      "Cleaning staff            401\n",
      "Private service staff     243\n",
      "Low-skill Laborers        127\n",
      "Waiters/barmen staff      123\n",
      "Secretaries                97\n",
      "Realty agents              63\n",
      "HR staff                   62\n",
      "IT staff                   41\n",
      "Name: occyp_type, dtype: int64 \n",
      "\n",
      "\n",
      "Laborers                 1699\n",
      "no_work                  1697\n",
      "NAN                      1455\n",
      "Sales staff               946\n",
      "Core staff                945\n",
      "Managers                  845\n",
      "Drivers                   563\n",
      "Medicine staff            343\n",
      "High skill tech staff     343\n",
      "Accountants               339\n",
      "Cooking staff             198\n",
      "Security staff            168\n",
      "Cleaning staff            148\n",
      "Private service staff     101\n",
      "Secretaries                54\n",
      "Waiters/barmen staff       50\n",
      "Low-skill Laborers         48\n",
      "HR staff                   23\n",
      "IT staff                   19\n",
      "Realty agents              16\n",
      "Name: occyp_type, dtype: int64 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = occype_process(train)\n",
    "test = occype_process(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c2c813",
   "metadata": {},
   "source": [
    "# 구간화 변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7754f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bin(df, variable, n):\n",
    "    \n",
    "    data = df\n",
    "    count, bin_dividers = np.histogram(data[variable], bins=n)\n",
    "    bin_names=[str(i) for i in range(n)]\n",
    "    data['%s_bin' % variable] = pd.cut(x=data[variable], bins=bin_dividers, labels=bin_names, include_lowest=True)\n",
    "    data['%s_bin' % variable] = pd.factorize(data['%s_bin' % variable])[0]\n",
    "    print(data['%s_bin' % variable], '\\n\\n')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73993e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# days_birth만 구간화 했을 떄 가장 성능이 좋았음\n",
    "train = make_bin(train, 'DAYS_BIRTH', n=10)\n",
    "test = make_bin(test, 'DAYS_BIRTH', n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7203f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불필요 변수 제거\n",
    "train = train.drop(['income_total', 'DAYS_EMPLOYED', 'FLAG_MOBIL'], axis=1)\n",
    "test = test.drop(['income_total', 'DAYS_EMPLOYED', 'FLAG_MOBIL'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce33956c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#전처리 완료된 최종 데이터\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5c86fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train.drop(['credit'],axis=1)\n",
    "train_y = train['credit']\n",
    "train_X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e698d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# object형 변수는 cat_features에 추가\n",
    "cat_features = [f for f in train_x.columns if train_x[f].dtype == 'object']\n",
    "\n",
    "def column_index(df, cat_features):\n",
    "    cols = df.columns.values\n",
    "    sidx = np.argsort(cols)\n",
    "    return sidx[np.searchsorted(cols, cat_features, sorter=sidx)]\n",
    "\n",
    "cat_features_idx = column_index(train_x, cat_features)    \n",
    "print(\"Cat features are: %s\" % [f for f in cat_features])\n",
    "print(cat_features_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0210bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_models={}\n",
    "\n",
    "def cat_kfold(max_depth, learning_rate, random_seed):\n",
    "    \n",
    "    folds=StratifiedKFold(n_splits=10, shuffle=True, random_state=55)\n",
    "    outcomes=[]\n",
    "    sub=np.zeros((test.shape[0], 3))  \n",
    "    \n",
    "    for seed in random_seed:\n",
    "        for n_fold, (train_index, val_index) in enumerate(folds.split(train_x, train_y)):\n",
    "            print(f'===================================={n_fold+1}============================================')\n",
    "            \n",
    "            X_train, X_val = train_x.iloc[train_index], train_x.iloc[val_index]\n",
    "            y_train, y_val = train_y.iloc[train_index], train_y.iloc[val_index]\n",
    "\n",
    "            # early_stopping 50에서 가장 좋은 점수를 내는 learning_rate를 활용\n",
    "            cat = CatBoostClassifier(n_estimators=3000, max_depth=max_depth, random_seed=seed, learning_rate=learning_rate, bootstrap_type ='Bernoulli')\n",
    "            cat.fit(X_train, y_train,\n",
    "                  eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "                  early_stopping_rounds=50, cat_features=cat_features,\n",
    "                  verbose=100)\n",
    "\n",
    "            cat_models[n_fold] = cat\n",
    "\n",
    "            # val 데이터 예측\n",
    "            predictions = cat.predict_proba(X_val)\n",
    "            # test 데이터 예측\n",
    "            test_predictions = cat.predict_proba(test)\n",
    "\n",
    "            # val 데이터 예측 logloss 값 저장\n",
    "            logloss=log_loss(to_categorical(y_val), predictions)\n",
    "            outcomes.append(logloss)\n",
    "            print(f\"FOLD {n_fold+1} : logloss:{logloss}\")\n",
    "\n",
    "            # test 데이터 예측 결과 종합\n",
    "            # 최종 적으로는 kolds 횟수 만큼 나눠서 평균 값을 활용\n",
    "            sub+=test_predictions\n",
    "\n",
    "            print(f'================================================================================\\n\\n')\n",
    "\n",
    "    # 저장된 val 데이터 예측 logloss 값의 평균 값으로 성능을 비교\n",
    "    mean_outcome=np.mean(outcomes)\n",
    "    print(\"Mean:{}\".format(mean_outcome))\n",
    "    \n",
    "    return sub/(folds.n_splits * len(random_seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3307ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(importance, names, model_type):\n",
    "    \n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "    \n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "    \n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "    \n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
    "    plt.title(model_type + 'FEATURE IMPORTANCE')\n",
    "    plt.xlabel('FEATURE IMPORTANCE')\n",
    "    plt.ylabel('FEATURE NAMES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bea132",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(cat_models[0].get_feature_importance(), train_x.columns,'CatBOOST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7715e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = CatBoostClassifier(n_estimators=443, max_depth=8, random_seed=2, learning_rate =0.04, bootstrap_type ='Bernoulli')\n",
    "cat.fit(train_x, train_y, cat_features=cat_features, verbose=50)\n",
    "test_predictions = cat.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7ac72c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb50e912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ecbbea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cb7e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77ac631",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
